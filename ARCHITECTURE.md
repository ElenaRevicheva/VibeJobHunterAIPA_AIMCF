# ğŸ— VibeJobHunter - Architecture

System design and technical architecture.

---

## ğŸ“ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Interface                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   CLI Commands   â”‚  Web Dashboard   â”‚   API Endpoints   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Core Application    â”‚
                â”‚  - ProfileManager     â”‚
                â”‚  - ApplicationManager â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚  AI     â”‚      â”‚  Scrapers â”‚     â”‚   Data    â”‚
    â”‚ Agents  â”‚      â”‚           â”‚     â”‚  Storage  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Claude  â”‚      â”‚ LinkedIn  â”‚     â”‚   JSON    â”‚
    â”‚ OpenAI  â”‚      â”‚  Indeed   â”‚     â”‚   Files   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Component Architecture

### 1. Core Layer (`src/core/`)

**Responsibilities**: Configuration, models, and core business logic

**Components**:
- `config.py` - Application settings and configuration
- `models.py` - Data models (Profile, JobPosting, Application, etc.)
- `profile_manager.py` - Profile management and resume parsing

**Key Features**:
- Pydantic models for type safety
- Environment-based configuration
- JSON serialization/deserialization
- Profile persistence

### 2. Agent Layer (`src/agents/`)

**Responsibilities**: AI-powered intelligence and decision making

**Components**:
- `job_matcher.py` - Job scoring and matching algorithm
- `content_generator.py` - Resume and cover letter generation
- `application_manager.py` - Application tracking and management

**Key Features**:
- Claude AI integration for intelligent analysis
- Context-aware content generation
- Match score calculation (0-100)
- Timeline tracking

### 3. Scraper Layer (`src/scrapers/`)

**Responsibilities**: Job discovery and data extraction

**Components**:
- `base_scraper.py` - Abstract base class
- `linkedin_scraper.py` - LinkedIn job scraping
- `indeed_scraper.py` - Indeed job scraping

**Key Features**:
- Async job fetching
- Rate limiting
- Error handling
- Standardized job data format

### 4. API Layer (`src/api/`)

**Responsibilities**: Web interface and REST API

**Components**:
- `app.py` - FastAPI application

**Key Features**:
- RESTful endpoints
- Web dashboard UI
- Real-time statistics
- CORS support

### 5. CLI Layer (`src/main.py`)

**Responsibilities**: Command-line interface

**Features**:
- Click-based commands
- Rich console output
- Interactive prompts
- Progress indicators

---

## ğŸ”„ Data Flow

### Job Search Flow

```
User Command
    â”‚
    â”œâ”€> Search Parameters
    â”‚       â”‚
    â”‚       â”œâ”€> LinkedIn Scraper â”€â”€â”
    â”‚       â”œâ”€> Indeed Scraper â”€â”€â”€â”€â”¤
    â”‚       â””â”€> [More sources]     â”‚
    â”‚                              â”‚
    â”‚   <â”€â”€ Raw Job Listings â”€â”€â”€â”€â”€â”€â”˜
    â”‚           â”‚
    â”‚           â”œâ”€> Job Matcher (AI Analysis)
    â”‚           â”‚       â”‚
    â”‚           â”‚       â”œâ”€> Calculate Match Score
    â”‚           â”‚       â”œâ”€> Generate Match Reasons
    â”‚           â”‚       â””â”€> Filter by Criteria
    â”‚           â”‚
    â”‚   <â”€â”€ Scored Jobs
    â”‚           â”‚
    â”‚           â””â”€> Save to data/jobs/
    â”‚
    â””â”€> Display Results
```

### Application Flow

```
User Applies
    â”‚
    â”œâ”€> Select Job
    â”‚       â”‚
    â”‚       â”œâ”€> Content Generator
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€> Tailor Resume (AI)
    â”‚       â”‚       â”œâ”€> Write Cover Letter (AI)
    â”‚       â”‚       â””â”€> Generate LinkedIn Message
    â”‚       â”‚
    â”‚   <â”€â”€ Generated Content
    â”‚           â”‚
    â”‚           â”œâ”€> Save Files
    â”‚           â”‚   - tailored_resumes/
    â”‚           â”‚   - cover_letters/
    â”‚           â”‚
    â”‚           â””â”€> Create Application Record
    â”‚                   â”‚
    â”‚                   â”œâ”€> Set Status: APPLIED
    â”‚                   â”œâ”€> Add to Timeline
    â”‚                   â””â”€> Save to data/applications/
    â”‚
    â””â”€> Display Confirmation
```

### Status Update Flow

```
Status Change
    â”‚
    â”œâ”€> Update Application
    â”‚       â”‚
    â”‚       â”œâ”€> Change Status
    â”‚       â”œâ”€> Add Timeline Event
    â”‚       â”œâ”€> Update Timestamps
    â”‚       â””â”€> Schedule Follow-up (if needed)
    â”‚
    â”œâ”€> Save Application
    â”‚
    â””â”€> Update Statistics
```

---

## ğŸ’¾ Data Architecture

### Storage Strategy: Local-First JSON

**Why JSON?**
- Human-readable
- Easy to backup
- No database setup
- Version control friendly
- Portable across systems

### Directory Structure

```
data/
â”œâ”€â”€ profiles/
â”‚   â””â”€â”€ profile.json                    # User profile
â”‚
â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ abc123def456.json               # Job posting 1
â”‚   â”œâ”€â”€ xyz789ghi012.json               # Job posting 2
â”‚   â””â”€â”€ ...                             # More jobs
â”‚
â”œâ”€â”€ applications/
â”‚   â”œâ”€â”€ abc123def456.json               # Application 1
â”‚   â”œâ”€â”€ xyz789ghi012.json               # Application 2
â”‚   â””â”€â”€ ...                             # More applications
â”‚
â””â”€â”€ stats/
    â”œâ”€â”€ 2025-01-15.json                 # Daily stats
    â”œâ”€â”€ 2025-01-16.json
    â””â”€â”€ ...
```

### Data Models

**Profile Schema**:
```json
{
  "name": "string",
  "email": "string",
  "location": "string",
  "skills": ["skill1", "skill2"],
  "experience_years": 10,
  "key_achievements": ["achievement1"],
  "target_roles": ["role1", "role2"],
  "resume_text": "full resume text",
  "created_at": "2025-01-15T10:00:00",
  "updated_at": "2025-01-15T10:00:00"
}
```

**JobPosting Schema**:
```json
{
  "id": "abc123",
  "title": "AI Engineer",
  "company": "StartupCo",
  "location": "Remote",
  "description": "full description",
  "requirements": ["req1", "req2"],
  "source": "linkedin",
  "url": "https://...",
  "match_score": 85.5,
  "match_reasons": ["reason1", "reason2"],
  "applied": false,
  "discovered_at": "2025-01-15T10:00:00"
}
```

**Application Schema**:
```json
{
  "id": "abc123",
  "job_id": "abc123",
  "job_title": "AI Engineer",
  "company": "StartupCo",
  "status": "applied",
  "applied_date": "2025-01-15T10:00:00",
  "timeline": [
    {
      "status": "applied",
      "timestamp": "2025-01-15T10:00:00",
      "note": "Application submitted"
    }
  ],
  "resume_version": "markdown content",
  "cover_letter_content": "letter content",
  "next_follow_up": "2025-01-22T10:00:00"
}
```

---

## ğŸ¤– AI Integration

### Claude API Usage

**Model**: `claude-3-5-sonnet-20241022`

**Use Cases**:
1. **Resume Parsing** (4K tokens)
   - Extract structured data from PDF
   - Identify skills, experience, achievements
   
2. **Job Matching** (1K tokens per job)
   - Calculate match score
   - Generate match reasons
   - Identify aligned/missing skills
   
3. **Resume Tailoring** (4K tokens)
   - Rewrite resume for specific job
   - Emphasize relevant experience
   - Optimize for ATS
   
4. **Cover Letter Generation** (2K tokens)
   - Personalized content
   - Company-specific references
   - Professional tone
   
5. **Interview Prep** (3K tokens)
   - Company research
   - Likely questions
   - Suggested answers

**Cost Optimization**:
- Cache profile data in prompts
- Batch similar requests
- Use appropriate token limits
- Retry logic for failures

---

## ğŸ”Œ External Integrations

### Job Platforms

**LinkedIn**:
- HTTP scraping (no official API for job search)
- BeautifulSoup for HTML parsing
- Rate limiting: 1 req/sec
- User-Agent spoofing

**Indeed**:
- HTTP scraping
- Similar to LinkedIn approach
- Rate limiting: 1 req/sec

**Future Integrations**:
- AngelList API
- Y Combinator jobs
- Twitter/X API
- Company career pages

### AI Services

**Anthropic Claude**:
- Primary AI for intelligent features
- REST API via `anthropic` Python SDK
- Streaming support for long responses

**OpenAI GPT** (Optional):
- Alternative AI backend
- Fallback option
- Embeddings for similarity search

---

## ğŸš¦ Error Handling

### Strategy

**Graceful Degradation**:
- Continue operation even if one component fails
- Fallback to simpler algorithms when AI fails
- Detailed error logging

**Retry Logic**:
- Exponential backoff for API calls
- Max 3 retries
- Skip failed jobs rather than crash

**User Feedback**:
- Clear error messages
- Suggestions for fixes
- Logs stored in `logs/`

---

## ğŸ” Security

### API Key Management
- Stored in `.env` (never committed)
- Loaded via `python-dotenv`
- No hardcoded credentials

### Data Privacy
- All data stored locally
- No cloud sync (unless user configures)
- Resume data only sent to Claude API
- No third-party analytics

### Scraping Ethics
- Respect robots.txt
- Rate limiting to avoid overload
- User-Agent identification
- Public data only

---

## âš¡ Performance

### Optimization Strategies

**Async Operations**:
- Concurrent job fetching
- Parallel AI requests
- Non-blocking I/O

**Caching**:
- Profile data cached in memory
- Job data persisted to disk
- Avoid re-parsing same resume

**Rate Limiting**:
- 1 req/sec to job platforms
- 5 req/sec to Claude (within limits)
- Configurable delays

---

## ğŸ“Š Monitoring & Logging

### Logging Strategy

**Levels**:
- DEBUG: Detailed debugging info
- INFO: General progress
- WARNING: Non-critical issues
- ERROR: Critical failures

**Destinations**:
- Console: INFO and above
- Files: All levels to `logs/app.log`
- Rotation: Daily log files

### Metrics Tracked
- Jobs discovered per run
- Match score distribution
- API call latency
- Success/failure rates
- Application conversion funnel

---

## ğŸ§ª Testing Strategy

### Test Coverage (Future)

**Unit Tests**:
- Model validation
- Scoring algorithm
- Content generation
- Data persistence

**Integration Tests**:
- Scraper functionality
- AI integration
- End-to-end workflows

**Manual Testing**:
- Resume parsing accuracy
- Cover letter quality
- UI/UX validation

---

## ğŸ”„ Deployment

### Requirements

**System**:
- Python 3.9+
- 2GB RAM minimum
- 1GB disk space

**External**:
- Internet connection
- Anthropic API access
- (Optional) LinkedIn account

### Installation

```bash
# Clone repo
git clone <repo>

# Install dependencies
pip install -r requirements.txt

# Configure
cp .env.example .env
# Edit .env with API keys

# Run setup
python setup.py
```

---

## ğŸ”® Future Architecture

### Planned Improvements

**Database**:
- SQLite for better querying
- Full-text search
- Relationship tracking

**Message Queue**:
- Celery for background jobs
- Scheduled tasks
- Async processing

**Microservices** (Optional):
- Separate scraper service
- Dedicated AI service
- API gateway

**Cloud Features** (Optional):
- Cloud sync
- Multi-device support
- Collaborative features

---

## ğŸ“š Technology Stack

### Core
- **Python 3.9+** - Main language
- **Pydantic** - Data validation
- **Click** - CLI framework
- **Rich** - Terminal UI

### AI/ML
- **Anthropic Claude** - Primary AI
- **OpenAI GPT** - Alternative
- **LangChain** - AI orchestration

### Web
- **FastAPI** - Web framework
- **Uvicorn** - ASGI server
- **Jinja2** - Templates

### Data
- **JSON** - Data storage
- **PyPDF2** - PDF parsing
- **python-docx** - Word docs

### Web Scraping
- **aiohttp** - Async HTTP
- **BeautifulSoup** - HTML parsing
- **Selenium** - Browser automation

---

## ğŸ¤ Contributing

### Code Style
- PEP 8 compliance
- Type hints everywhere
- Docstrings for all public functions
- Clear variable names

### Project Structure
- Modular design
- Separation of concerns
- Single responsibility principle
- DRY (Don't Repeat Yourself)

---

**Questions? Check README.md or open an issue!** ğŸ“–
